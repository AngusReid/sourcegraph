package graphstoreutil

import (
	"bytes"
	"crypto/aes"
	"crypto/cipher"
	"crypto/sha256"
	"encoding/base64"
	"encoding/xml"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strconv"
	"strings"
	"time"

	"github.com/sqs/s3/s3util"
	"sourcegraph.com/sourcegraph/rwvfs"
	"sourcegraph.com/sourcegraph/srclib/store"
)

const (
	aesBlockSize = 16
	ivLen        = 6
)

var zeroPad = bytes.Repeat([]byte{'\x00'}, aesBlockSize-ivLen)

// EvenlyDistributedRepoPaths stores repos underneath paths whose
// prefixes are evenly distributed, even if the repo identifiers are
// not. The prefix for each repo is generated by hashing and
// AES-encrypting the repo identifier.
type EvenlyDistributedRepoPaths struct{ Key [aesBlockSize]byte }

func (e *EvenlyDistributedRepoPaths) crypt(iv []byte, in []byte) []byte {
	if in == nil || len(in) == 0 {
		panic("empty `in`")
	}
	c, err := aes.NewCipher(e.Key[:])
	if err != nil {
		panic("aes.NewCipher: " + err.Error())
	}
	ctr := cipher.NewCTR(c, iv)
	ctr.XORKeyStream(in, in)
	return in
}

var b64 = base64.URLEncoding

// RepoToPath implements store.RepoPaths.
func (e *EvenlyDistributedRepoPaths) RepoToPath(repo string) []string {
	iv0 := sha256.Sum224([]byte(repo))
	iv := iv0[:aesBlockSize]
	copy(iv[ivLen:], zeroPad)
	c := append(iv[:ivLen], e.crypt(iv, []byte(repo))...)
	h := make([]byte, b64.EncodedLen(len(c)))
	b64.Encode(h, c)
	return []string{string(h)}
}

// PathToRepo implements store.RepoPaths.
func (e *EvenlyDistributedRepoPaths) PathToRepo(path []string) string {
	c, err := b64.DecodeString(path[0])
	if err != nil {
		panic(fmt.Sprintf("hex-decoding path %q: %s", path, err))
	}
	iv := make([]byte, aesBlockSize)
	copy(iv, c[:ivLen])
	return string(e.crypt(iv, c[ivLen:]))
}

// ListRepoPaths implements store.RepoPaths.
func (e *EvenlyDistributedRepoPaths) ListRepoPaths(vfs rwvfs.WalkableFileSystem, after string, max int) ([][]string, error) {
	entries, err := vfs.ReadDir(".")
	if err != nil {
		return nil, err
	}
	paths := make([][]string, len(entries))
	for i, e := range entries {
		paths[i] = []string{e.Name()}
	}
	return paths, nil
}

// s3RepoPaths wraps store.RepoPaths with an optimized
// ListRepoPaths for S3.
type s3RepoPaths struct {
	bucket *url.URL
	config *s3util.Config
	client *http.Client
	delim  string
	store.RepoPaths
}

// ListRepoPaths implements RepoPaths for S3.
func (c *s3RepoPaths) ListRepoPaths(vfs rwvfs.WalkableFileSystem, after string, max int) ([][]string, error) {
	// We want to omit keys under "after", so make "after" into a
	// string that sorts lexicographically AFTER the keys underneath
	// the original "after" value.
	if after != "" {
		after += "\xff"
	}

	q := make(url.Values)
	q.Set("marker", after)
	q.Set("max-keys", strconv.Itoa(max))
	q.Set("delimiter", c.delim)
	u := c.bucket.ResolveReference(&url.URL{RawQuery: q.Encode()})

	req, err := http.NewRequest("GET", u.String(), nil)
	if err != nil {
		return nil, err
	}
	req.Header.Set("Date", time.Now().UTC().Format(http.TimeFormat))
	c.config.Sign(req, *c.config.Keys)
	resp, err := c.client.Do(req)
	if err != nil {
		return nil, err
	}
	if resp.StatusCode != 200 {
		resp.Body.Close()
		return nil, newRespError(resp)
	}

	result := struct{ CommonPrefixes []struct{ Prefix string } }{}
	if err := xml.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, err
	}

	if err := resp.Body.Close(); err != nil {
		return nil, err
	}

	entries := make([][]string, len(result.CommonPrefixes))
	for i, v := range result.CommonPrefixes {
		entries[i] = strings.Split(strings.TrimSuffix(v.Prefix, "/"), "/")
	}
	return entries, nil
}

type respError struct {
	r *http.Response
	b bytes.Buffer
}

func newRespError(r *http.Response) *respError {
	e := new(respError)
	e.r = r
	io.Copy(&e.b, r.Body)
	r.Body.Close()
	return e
}

func (e *respError) Error() string {
	return fmt.Sprintf(
		"unwanted http status %d: %q",
		e.r.StatusCode,
		e.b.String(),
	)
}
